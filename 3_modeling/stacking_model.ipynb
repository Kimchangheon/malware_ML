{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stud/.conda/envs/mlsec_27/lib/python2.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(998, 103) (937, 72)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import model\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "ngram = pd.read_csv('../2-feature_eng/ngram.csv')\n",
    "pe_nor = pd.read_csv('../2-feature_eng/normal_pe.csv')\n",
    "pe_mal = pd.read_csv('../2-feature_eng/malware_pe.csv')\n",
    "pe_all = pd.concat([pe_nor, pe_mal])  \n",
    "pe_all = pe_all.dropna()\n",
    "\n",
    "print ngram.shape, pe_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def hot_encoding(df):\n",
    "\n",
    "    enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    lab = LabelEncoder()    \n",
    "\n",
    "    dat = df['packer_type']\n",
    "    lab.fit(dat)\n",
    "    lab_dat = lab.transform(dat)\n",
    "\n",
    "    df = df.drop('packer_type', 1)\n",
    "    lab_dat = lab_dat.reshape(len(lab_dat), 1)\n",
    "    enc_dat = enc.fit_transform(lab_dat)\n",
    "    enc_dat = pd.DataFrame(enc_dat, columns=lab.classes_)\n",
    "\n",
    "    df = df.reset_index(drop=True)\n",
    "    enc_dat = enc_dat.reset_index(drop=True)\n",
    "    \n",
    "    df = pd.concat([df, enc_dat], axis=1)\n",
    "\n",
    "    return df, lab.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(937, 188)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_list = dict(zip(ngram['filename'], ngram['class']))\n",
    "pe_list    = dict(zip(pe_all['filename'], pe_all['class']))\n",
    "\n",
    "only_ngram = []\n",
    "\n",
    "for k, v in ngram_list.items():\n",
    "    try:\n",
    "        pe_list[k]\n",
    "    except:\n",
    "        only_ngram.append(k)\n",
    "        \n",
    "for i in only_ngram:\n",
    "    i = str(i)\n",
    "    ngram = ngram[ngram.filename != i]\n",
    "    \n",
    "pe_all = pe_all.sort_values(by=['MD5'])\n",
    "ngram = ngram.sort_values(by=['MD5'])\n",
    "\n",
    "pe_all = pe_all.drop(['filename', 'MD5', 'class'], 1) \n",
    "ngram = ngram.drop(['filename', 'MD5'], 1) \n",
    "\n",
    "pe_all = pe_all.reset_index(drop=True)\n",
    "ngram = ngram.reset_index(drop=True)\n",
    "\n",
    "df = pd.concat([pe_all, ngram], axis=1)\n",
    "df, enc_class = hot_encoding(df)\n",
    "\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('patterns.csv', 'wb') as f:\n",
    "    wr = csv.writer(f, quoting=csv.QUOTE_ALL)\n",
    "    wr.writerow(enc_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(937, 187) (937,)\n",
      "(749, 187) (749,) (188, 187) (188,)\n"
     ]
    }
   ],
   "source": [
    "Y = df['class']\n",
    "X = df.drop('class', axis=1)\n",
    "\n",
    "print X.shape, Y.shape\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "print x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearch for RandomForest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'n_estimators':[100, 200, 500, 1000], 'max_features':['auto', None]}\n",
    "rfc = RandomForestClassifier()\n",
    "clf = GridSearchCV(rfc, parameters, cv=10)\n",
    "clf.fit(x_train, y_train)\n",
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=1e-06, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearch for SVM Model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'C':[10, 100, 1000, 10000], 'gamma':[1e-3, 1e-4, 1e-5, 1e-6]}\n",
    "svc = SVC()\n",
    "clf = GridSearchCV(svc, parameters, cv=10)\n",
    "clf.fit(x_train, y_train)\n",
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(749, 4) (749,) (188, 4) (188,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "clf_rf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "\n",
    "clf_svm = SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape='ovr', degree=3, gamma=1e-06, kernel='rbf',\n",
    "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
    "  tol=0.001, verbose=False) \n",
    "\n",
    "clf_rf.fit(x_train, y_train)\n",
    "clf_svm.fit(x_train, y_train)\n",
    "\n",
    "joblib.dump(clf_rf, 'rf_model.joblib')\n",
    "joblib.dump(clf_svm, 'svm_model.joblib')\n",
    "\n",
    "rf_pred = clf_rf.predict_proba(x_train)\n",
    "svm_pred = clf_svm.predict_proba(x_train)\n",
    "X_train = np.column_stack((rf_pred, svm_pred))\n",
    "\n",
    "rf_pred = clf_rf.predict_proba(x_test)\n",
    "svm_pred = clf_svm.predict_proba(x_test)\n",
    "X_test = np.column_stack((rf_pred, svm_pred))\n",
    "\n",
    "print X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 cost:  0.7694505\n",
      "Epoch : 2 cost:  0.0323754\n",
      "Epoch : 3 cost:  0.009921551\n",
      "Epoch : 4 cost:  0.0029740625\n",
      "Epoch : 5 cost:  0.0012898108\n",
      "Epoch : 6 cost:  0.00073662767\n",
      "Epoch : 7 cost:  0.00045024938\n",
      "Epoch : 8 cost:  0.00026204853\n",
      "Epoch : 9 cost:  0.00020750012\n",
      "Epoch : 10 cost:  0.00019247903\n",
      "Epoch : 11 cost:  0.00018095018\n",
      "Epoch : 12 cost:  0.00017286284\n",
      "Epoch : 13 cost:  0.00016684696\n",
      "Epoch : 14 cost:  0.00016155062\n",
      "Epoch : 15 cost:  0.00015663318\n",
      "Accuracy:  0.9468085\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "learning_rate = 0.001\n",
    "batch_size = 128\n",
    "training_epochs = 15\n",
    "keep_prob = 0.5\n",
    "\n",
    "x_train = X_train\n",
    "y_train = y_train\n",
    "x_test = X_test\n",
    "y_test = y_test\n",
    "\n",
    "y_train = y_train.to_frame()\n",
    "y_test = y_test.to_frame()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 4])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([4, 1024]), name='weight1')\n",
    "b1 = tf.Variable(tf.truncated_normal([1024]), name='bias1')\n",
    "L1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([1024, 128]), name='weight4')\n",
    "b2 = tf.Variable(tf.truncated_normal([128]), name='bias4')\n",
    "L2 = tf.sigmoid(tf.matmul(L1, W2) + b2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([128, 1]), name='weight5')\n",
    "b3 = tf.Variable(tf.truncated_normal([1]), name='bias5')\n",
    "\n",
    "output = tf.sigmoid(tf.add(tf.matmul(L2, W3), b3))\n",
    "\n",
    "cost = -tf.reduce_mean(Y * tf.log(output) + (1 - Y) * tf.log(1 - output))\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(output > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(len(x_train) / batch_size)\n",
    "\n",
    "        for i in range(total_batch-1):\n",
    "            batch_xs = x_train[i*batch_size:(i+1)*batch_size]\n",
    "            batch_ys = y_train[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "            _ , c =sess.run([train, cost], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "            \n",
    "        print \"Epoch :\", epoch+1, \"cost: \", c\n",
    "\n",
    "    acc =  sess.run(accuracy, feed_dict={X: x_test, Y: y_test})\n",
    "    print \"Accuracy: \", acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
